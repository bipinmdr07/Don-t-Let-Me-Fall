{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unity ML Agents\n",
    "## Proximal Policy Optimization (PPO)\n",
    "Contains an implementation of PPO as described [here](https://arxiv.org/abs/1707.06347)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from ppo.history import *\n",
    "from ppo.models import *\n",
    "from ppo.trainer import Trainer\n",
    "from unityagents import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General parameters\n",
    "max_steps = 8e6 # Set maximum number of steps to run environment.\n",
    "run_path = \"ppo\" # The sub-directory name for model and summary statistics\n",
    "load_model = False # Whether to load a saved model.\n",
    "train_model = True # Whether to train the model.\n",
    "summary_freq = 10000 # Frequency at which to save training statistics.\n",
    "save_freq = 50000 # Frequency at which to save model.\n",
    "env_name = \"Runner\" # Name of the training environment file.\n",
    "curriculum_file = None\n",
    "\n",
    "### Algorithm-specific parameters for tuning\n",
    "gamma = 0.99 # Reward discount rate.\n",
    "lambd = 0.95 # Lambda parameter for GAE.\n",
    "time_horizon = 2048 # How many steps to collect per agent before adding to buffer.\n",
    "beta = 1e-3 # Strength of entropy regularization\n",
    "num_epoch = 5 # Number of gradient descent steps per batch of experiences.\n",
    "num_layers = 2 # Number of hidden layers between state/observation encoding and value/policy layers.\n",
    "epsilon = 0.2 # Acceptable threshold around ratio of old and new policy probabilities.\n",
    "buffer_size = 2048 # How large the experience buffer should be before gradient descent.\n",
    "learning_rate = 3e-4 # Model learning rate.\n",
    "hidden_units = 16 # Number of units in hidden layer.\n",
    "batch_size = 64 # How many experiences per gradient descent update step.\n",
    "normalize = False\n",
    "\n",
    "### Logging dictionary for hyperparameters\n",
    "hyperparameter_dict = {'max_steps':max_steps, 'run_path':run_path, 'env_name':env_name,\n",
    "    'curriculum_file':curriculum_file, 'gamma':gamma, 'lambd':lambd, 'time_horizon':time_horizon,\n",
    "    'beta':beta, 'num_epoch':num_epoch, 'epsilon':epsilon, 'buffe_size':buffer_size,\n",
    "    'leaning_rate':learning_rate, 'hidden_units':hidden_units, 'batch_size':batch_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'RunnerAcademy' started successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: RunnerAcademy\n",
      "        Number of brains: 1\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: RunnerBrain\n",
      "        Number of observations (per agent): 0\n",
      "        State space type: continuous\n",
      "        State space size (per agent): 5\n",
      "        Action space type: discrete\n",
      "        Action space size (per agent): 2\n",
      "        Memory space size (per agent): 0\n",
      "        Action descriptions: NotJump, Jump\n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_name, curriculum=curriculum_file)\n",
    "print(str(env))\n",
    "brain_name = env.external_brain_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Agent(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10000. Mean Reward: -0.018047882136279954. Std of Reward: 0.9720761805733418.\n",
      "Step: 20000. Mean Reward: 0.2759615384615384. Std of Reward: 1.1796400505537104.\n",
      "Step: 30000. Mean Reward: 0.6925249169435216. Std of Reward: 1.5113064259661313.\n",
      "Step: 40000. Mean Reward: 1.1227272727272728. Std of Reward: 1.7716859175188984.\n",
      "Step: 50000. Mean Reward: 1.2877216916780354. Std of Reward: 1.7869370225456962.\n",
      "Saved Model\n",
      "Step: 60000. Mean Reward: 1.8718792866941016. Std of Reward: 1.9081564603918149.\n",
      "Step: 70000. Mean Reward: 2.0207496653279784. Std of Reward: 1.9274468550649122.\n",
      "Step: 80000. Mean Reward: 1.9873357228195938. Std of Reward: 1.7529411225270692.\n",
      "Step: 90000. Mean Reward: 2.1304054054054054. Std of Reward: 1.8337438932722552.\n",
      "Step: 100000. Mean Reward: 2.164810281517748. Std of Reward: 1.7344326991129715.\n",
      "Saved Model\n",
      "Step: 110000. Mean Reward: 2.282439335887612. Std of Reward: 1.7996721855844617.\n",
      "Step: 120000. Mean Reward: 2.252948717948718. Std of Reward: 1.8573151348628654.\n",
      "Step: 130000. Mean Reward: 2.376964047936085. Std of Reward: 1.8240173386520904.\n",
      "Step: 140000. Mean Reward: 2.326595744680851. Std of Reward: 2.0079836503626556.\n",
      "Step: 150000. Mean Reward: 2.3869883040935673. Std of Reward: 2.080000560864477.\n",
      "Saved Model\n",
      "Step: 160000. Mean Reward: 2.4493372606774666. Std of Reward: 2.0851064547145666.\n",
      "Step: 170000. Mean Reward: 2.3263120567375886. Std of Reward: 2.062713358437011.\n",
      "Step: 180000. Mean Reward: 2.581460674157303. Std of Reward: 2.130213459558675.\n",
      "Step: 190000. Mean Reward: 2.4256880733944954. Std of Reward: 2.1277198605179364.\n",
      "Step: 200000. Mean Reward: 2.5571316614420065. Std of Reward: 2.2499077135167966.\n",
      "Saved Model\n",
      "Step: 210000. Mean Reward: 2.680298013245033. Std of Reward: 2.380719167026575.\n",
      "Step: 220000. Mean Reward: 2.8534542314335063. Std of Reward: 2.504447888348395.\n",
      "Step: 230000. Mean Reward: 2.6440235690235694. Std of Reward: 2.3739577843201136.\n",
      "Step: 240000. Mean Reward: 2.708390410958904. Std of Reward: 2.564277745180619.\n",
      "Step: 250000. Mean Reward: 2.9649906890130353. Std of Reward: 2.8966965146934753.\n",
      "Saved Model\n",
      "Step: 260000. Mean Reward: 2.900853889943074. Std of Reward: 2.801379477124937.\n",
      "Step: 270000. Mean Reward: 2.6956106870229006. Std of Reward: 2.8580173506610627.\n",
      "Step: 280000. Mean Reward: 2.7718511450381675. Std of Reward: 2.6733264381698265.\n",
      "Step: 290000. Mean Reward: 2.9036380597014926. Std of Reward: 2.6326932062534274.\n",
      "Step: 300000. Mean Reward: 2.9371401151631478. Std of Reward: 2.784955413989769.\n",
      "Saved Model\n",
      "Step: 310000. Mean Reward: 3.041269841269841. Std of Reward: 3.0022698381647746.\n",
      "Step: 320000. Mean Reward: 2.8875. Std of Reward: 2.9744769832095543.\n",
      "Step: 330000. Mean Reward: 3.0459710743801653. Std of Reward: 3.1882628380958717.\n",
      "Step: 340000. Mean Reward: 3.0536919831223623. Std of Reward: 3.0366419240944094.\n",
      "Step: 350000. Mean Reward: 2.9140889830508474. Std of Reward: 3.1442572107472784.\n",
      "Saved Model\n",
      "Step: 360000. Mean Reward: 3.29296875. Std of Reward: 3.2759541792793323.\n",
      "Step: 370000. Mean Reward: 3.3878464818763327. Std of Reward: 3.3865391775624953.\n",
      "Step: 380000. Mean Reward: 3.4137634408602153. Std of Reward: 3.405772113042101.\n",
      "Step: 390000. Mean Reward: 3.5738770685579198. Std of Reward: 3.4561039440221553.\n",
      "Step: 400000. Mean Reward: 3.5129672897196262. Std of Reward: 3.4146265006757264.\n",
      "Saved Model\n",
      "Step: 410000. Mean Reward: 3.7279411764705883. Std of Reward: 3.8005164350401617.\n",
      "Step: 420000. Mean Reward: 3.5932242990654206. Std of Reward: 3.6102448173605506.\n",
      "Step: 430000. Mean Reward: 3.682640586797066. Std of Reward: 3.7460139363281137.\n",
      "Step: 440000. Mean Reward: 4.11952736318408. Std of Reward: 4.065148626889796.\n",
      "Step: 450000. Mean Reward: 3.9893150684931507. Std of Reward: 4.316593763912659.\n",
      "Saved Model\n",
      "Step: 460000. Mean Reward: 3.876767676767676. Std of Reward: 3.948155579682677.\n",
      "Step: 470000. Mean Reward: 4.358567415730337. Std of Reward: 4.268330058351645.\n",
      "Step: 480000. Mean Reward: 4.400739644970414. Std of Reward: 4.4020948197463605.\n",
      "Step: 490000. Mean Reward: 4.078493150684932. Std of Reward: 3.6076321955227457.\n",
      "Step: 500000. Mean Reward: 4.697151898734177. Std of Reward: 4.728948165192623.\n",
      "Saved Model\n",
      "Step: 510000. Mean Reward: 5.085641891891892. Std of Reward: 5.10457911745456.\n",
      "Step: 520000. Mean Reward: 4.70404984423676. Std of Reward: 4.688625374011777.\n",
      "Step: 530000. Mean Reward: 5.461660777385159. Std of Reward: 5.499051161147156.\n",
      "Step: 540000. Mean Reward: 4.898220064724919. Std of Reward: 5.128433500121041.\n",
      "Step: 550000. Mean Reward: 5.3573476702508955. Std of Reward: 5.41469606413315.\n",
      "Saved Model\n",
      "Step: 560000. Mean Reward: 6.0886274509803915. Std of Reward: 5.6659533644280815.\n",
      "Step: 570000. Mean Reward: 5.782490272373541. Std of Reward: 5.794092055530345.\n",
      "Step: 580000. Mean Reward: 6.457083333333333. Std of Reward: 5.84782828575893.\n",
      "Step: 590000. Mean Reward: 7.034051724137932. Std of Reward: 6.643458667463066.\n",
      "Step: 600000. Mean Reward: 6.889958158995816. Std of Reward: 6.264245989943012.\n",
      "Saved Model\n",
      "Step: 610000. Mean Reward: 7.13141592920354. Std of Reward: 6.324430068730266.\n",
      "Step: 620000. Mean Reward: 7.20438596491228. Std of Reward: 6.435581808931663.\n",
      "Step: 630000. Mean Reward: 6.934753363228698. Std of Reward: 6.354491777187629.\n",
      "Step: 640000. Mean Reward: 7.400462962962963. Std of Reward: 6.79825513891715.\n",
      "Step: 650000. Mean Reward: 7.764454976303317. Std of Reward: 6.73164994328087.\n",
      "Saved Model\n",
      "Step: 660000. Mean Reward: 8.36560975609756. Std of Reward: 7.262447698910954.\n",
      "Step: 670000. Mean Reward: 8.28142857142857. Std of Reward: 7.221641605825727.\n",
      "Step: 680000. Mean Reward: 8.537626262626262. Std of Reward: 7.517438374799372.\n",
      "Step: 690000. Mean Reward: 8.416237113402062. Std of Reward: 7.267659386218269.\n",
      "Step: 700000. Mean Reward: 9.386458333333334. Std of Reward: 7.362572435858535.\n",
      "Saved Model\n",
      "Step: 710000. Mean Reward: 9.650523560209423. Std of Reward: 7.63553107546677.\n",
      "Step: 720000. Mean Reward: 10.122972972972974. Std of Reward: 7.70821950376275.\n",
      "Step: 730000. Mean Reward: 9.96524064171123. Std of Reward: 8.016771878955012.\n",
      "Step: 740000. Mean Reward: 10.756460674157303. Std of Reward: 8.07461693189021.\n",
      "Step: 750000. Mean Reward: 10.491340782122906. Std of Reward: 7.538672763100872.\n",
      "Saved Model\n",
      "Step: 760000. Mean Reward: 10.90635838150289. Std of Reward: 7.656910817712755.\n",
      "Step: 770000. Mean Reward: 12.076923076923077. Std of Reward: 7.953031501205788.\n",
      "Step: 780000. Mean Reward: 11.817732558139534. Std of Reward: 8.2542002752713.\n",
      "Step: 790000. Mean Reward: 10.634180790960452. Std of Reward: 8.126453179465756.\n",
      "Step: 800000. Mean Reward: 12.033333333333335. Std of Reward: 7.867883863608312.\n",
      "Saved Model\n",
      "Step: 810000. Mean Reward: 10.650546448087432. Std of Reward: 7.746943675632109.\n",
      "Step: 820000. Mean Reward: 11.914880952380955. Std of Reward: 8.132385946098713.\n",
      "Step: 830000. Mean Reward: 11.895481927710842. Std of Reward: 7.91548890004792.\n",
      "Step: 840000. Mean Reward: 11.07294117647059. Std of Reward: 8.454589957501248.\n",
      "Step: 850000. Mean Reward: 12.430909090909093. Std of Reward: 8.057649241234433.\n",
      "Saved Model\n",
      "Step: 860000. Mean Reward: 11.504120879120876. Std of Reward: 8.444638525806896.\n",
      "Step: 870000. Mean Reward: 11.214245810055866. Std of Reward: 7.803741823149373.\n",
      "Step: 880000. Mean Reward: 11.707309941520469. Std of Reward: 7.636863644902719.\n",
      "Step: 890000. Mean Reward: 11.722352941176469. Std of Reward: 7.804811886350297.\n",
      "Step: 900000. Mean Reward: 11.715384615384616. Std of Reward: 7.881965783697909.\n",
      "Saved Model\n",
      "Step: 910000. Mean Reward: 11.185955056179775. Std of Reward: 8.47025028072989.\n",
      "Step: 920000. Mean Reward: 12.3659509202454. Std of Reward: 7.775448432655156.\n",
      "Step: 930000. Mean Reward: 12.187356321839077. Std of Reward: 7.9982189770016445.\n",
      "Step: 940000. Mean Reward: 12.470481927710846. Std of Reward: 7.735918167110326.\n",
      "Step: 950000. Mean Reward: 13.699068322981368. Std of Reward: 8.083899096216902.\n",
      "Saved Model\n",
      "Step: 960000. Mean Reward: 13.667610062893079. Std of Reward: 7.8435089903633886.\n",
      "Step: 970000. Mean Reward: 12.387499999999998. Std of Reward: 8.230980763639005.\n",
      "Step: 980000. Mean Reward: 11.872647058823528. Std of Reward: 8.262824367157476.\n",
      "Step: 990000. Mean Reward: 12.112424242424243. Std of Reward: 8.176621155280953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1000000. Mean Reward: 13.699074074074074. Std of Reward: 7.877776743892389.\n",
      "Saved Model\n",
      "Step: 1010000. Mean Reward: 13.147256097560973. Std of Reward: 8.37814602914234.\n",
      "Step: 1020000. Mean Reward: 12.272701149425286. Std of Reward: 7.950718477784708.\n",
      "Step: 1030000. Mean Reward: 13.302760736196321. Std of Reward: 8.215125679157193.\n",
      "Step: 1040000. Mean Reward: 12.474561403508773. Std of Reward: 8.15492777588222.\n",
      "Step: 1050000. Mean Reward: 13.20670731707317. Std of Reward: 7.911080767779881.\n",
      "Saved Model\n",
      "Step: 1060000. Mean Reward: 12.5. Std of Reward: 7.665901229905501.\n",
      "Step: 1070000. Mean Reward: 12.993072289156625. Std of Reward: 7.897763345545633.\n",
      "Step: 1080000. Mean Reward: 13.54940119760479. Std of Reward: 8.123187016565995.\n",
      "Step: 1090000. Mean Reward: 13.500937500000001. Std of Reward: 8.158435955873758.\n",
      "Step: 1100000. Mean Reward: 12.389457831325302. Std of Reward: 7.611980906473094.\n",
      "Saved Model\n",
      "Step: 1110000. Mean Reward: 12.084782608695651. Std of Reward: 7.904537268227072.\n",
      "Step: 1120000. Mean Reward: 12.931818181818182. Std of Reward: 8.075848939161396.\n",
      "Step: 1130000. Mean Reward: 13.321341463414635. Std of Reward: 8.34579465625523.\n",
      "Step: 1140000. Mean Reward: 13.482407407407411. Std of Reward: 7.949012812809949.\n",
      "Step: 1150000. Mean Reward: 13.629999999999999. Std of Reward: 7.864447812398489.\n",
      "Saved Model\n",
      "Step: 1160000. Mean Reward: 13.2259375. Std of Reward: 7.912908701678147.\n",
      "Step: 1170000. Mean Reward: 14.178571428571429. Std of Reward: 8.699817436304176.\n",
      "Step: 1180000. Mean Reward: 13.991666666666667. Std of Reward: 8.291832308042135.\n",
      "Step: 1190000. Mean Reward: 13.86121794871795. Std of Reward: 7.784381086587187.\n",
      "Step: 1200000. Mean Reward: 13.937812500000001. Std of Reward: 8.034372927605721.\n",
      "Saved Model\n",
      "Step: 1210000. Mean Reward: 12.772485207100592. Std of Reward: 8.488641752021337.\n",
      "Step: 1220000. Mean Reward: 14.06572327044025. Std of Reward: 8.105402613128174.\n",
      "Step: 1230000. Mean Reward: 13.729936305732487. Std of Reward: 7.856738476390117.\n",
      "Step: 1240000. Mean Reward: 12.881871345029241. Std of Reward: 8.189048742380601.\n",
      "Step: 1250000. Mean Reward: 14.485093167701862. Std of Reward: 8.413636603273337.\n",
      "Saved Model\n",
      "Step: 1260000. Mean Reward: 14.01. Std of Reward: 8.081007440288618.\n",
      "Step: 1270000. Mean Reward: 13.910576923076924. Std of Reward: 8.001846761231851.\n",
      "Step: 1280000. Mean Reward: 14.24458598726115. Std of Reward: 8.021711341981282.\n",
      "Step: 1290000. Mean Reward: 14.313888888888888. Std of Reward: 7.862836971915009.\n",
      "Step: 1300000. Mean Reward: 13.542073170731708. Std of Reward: 8.457978876633168.\n",
      "Saved Model\n",
      "Step: 1310000. Mean Reward: 13.322670807453415. Std of Reward: 8.10795551025217.\n",
      "Step: 1320000. Mean Reward: 14.7390625. Std of Reward: 7.717621216805975.\n",
      "Step: 1330000. Mean Reward: 14.011949685534589. Std of Reward: 7.74250796138174.\n",
      "Step: 1340000. Mean Reward: 14.39151515151515. Std of Reward: 7.950535762855047.\n",
      "Step: 1350000. Mean Reward: 14.04409937888199. Std of Reward: 8.191436937174936.\n",
      "Saved Model\n",
      "Step: 1360000. Mean Reward: 14.141104294478527. Std of Reward: 8.25952307823643.\n",
      "Step: 1370000. Mean Reward: 14.86496815286624. Std of Reward: 8.24870085306268.\n",
      "Step: 1380000. Mean Reward: 14.27791411042945. Std of Reward: 7.945879238703452.\n",
      "Step: 1390000. Mean Reward: 14.005625. Std of Reward: 8.134169801484045.\n",
      "Step: 1400000. Mean Reward: 13.73865030674847. Std of Reward: 7.875007645557681.\n",
      "Saved Model\n",
      "Step: 1410000. Mean Reward: 13.551829268292684. Std of Reward: 7.911266453462426.\n",
      "Step: 1420000. Mean Reward: 13.579320987654318. Std of Reward: 7.881273016065173.\n",
      "Step: 1430000. Mean Reward: 13.581402439024387. Std of Reward: 8.559271744094957.\n",
      "Step: 1440000. Mean Reward: 13.987195121951217. Std of Reward: 8.379971443922216.\n",
      "Step: 1450000. Mean Reward: 13.435928143712577. Std of Reward: 7.8914641337636064.\n",
      "Saved Model\n",
      "Step: 1460000. Mean Reward: 12.535588235294119. Std of Reward: 8.32012344053524.\n",
      "Step: 1470000. Mean Reward: 13.108895705521473. Std of Reward: 8.33555272740394.\n",
      "Step: 1480000. Mean Reward: 13.658282208588957. Std of Reward: 7.935043545412814.\n",
      "Step: 1490000. Mean Reward: 13.01859756097561. Std of Reward: 8.006000332616011.\n",
      "Step: 1500000. Mean Reward: 13.670625000000001. Std of Reward: 7.701473859552793.\n",
      "Saved Model\n",
      "Step: 1510000. Mean Reward: 13.776875. Std of Reward: 8.49052208255623.\n",
      "Step: 1520000. Mean Reward: 14.270625. Std of Reward: 7.532503293021184.\n",
      "Step: 1530000. Mean Reward: 14.060691823899369. Std of Reward: 8.288497684200818.\n",
      "Step: 1540000. Mean Reward: 13.408841463414635. Std of Reward: 8.36202022207423.\n",
      "Step: 1550000. Mean Reward: 14.218471337579619. Std of Reward: 8.17772196376805.\n",
      "Saved Model\n",
      "Step: 1560000. Mean Reward: 15.02625. Std of Reward: 8.40993450851432.\n",
      "Step: 1570000. Mean Reward: 14.215723270440252. Std of Reward: 8.294561638734542.\n",
      "Step: 1580000. Mean Reward: 13.66848484848485. Std of Reward: 8.66370384829621.\n",
      "Step: 1590000. Mean Reward: 14.538709677419355. Std of Reward: 7.966959083913074.\n",
      "Step: 1600000. Mean Reward: 13.028703703703702. Std of Reward: 8.611121515326252.\n",
      "Saved Model\n",
      "Step: 1610000. Mean Reward: 13.866981132075473. Std of Reward: 8.05403885201907.\n",
      "Step: 1620000. Mean Reward: 14.493037974683546. Std of Reward: 8.374256944846197.\n",
      "Step: 1630000. Mean Reward: 14.655828220858897. Std of Reward: 8.33531071299375.\n",
      "Step: 1640000. Mean Reward: 14.13184713375796. Std of Reward: 8.544089760559897.\n",
      "Step: 1650000. Mean Reward: 14.55474683544304. Std of Reward: 8.334585157404913.\n",
      "Saved Model\n",
      "Step: 1660000. Mean Reward: 13.903416149068322. Std of Reward: 8.268801508806298.\n",
      "Step: 1670000. Mean Reward: 13.624840764331212. Std of Reward: 8.386979262701676.\n",
      "Step: 1680000. Mean Reward: 14.0578125. Std of Reward: 8.239063863075934.\n",
      "Step: 1690000. Mean Reward: 14.888782051282055. Std of Reward: 7.703555151885354.\n",
      "Step: 1700000. Mean Reward: 13.767177914110428. Std of Reward: 8.189583351515145.\n",
      "Saved Model\n",
      "Step: 1710000. Mean Reward: 14.004088050314468. Std of Reward: 8.122007854572132.\n",
      "Step: 1720000. Mean Reward: 13.878658536585366. Std of Reward: 7.857672693087656.\n",
      "Step: 1730000. Mean Reward: 14.669230769230767. Std of Reward: 7.960500365865872.\n",
      "Step: 1740000. Mean Reward: 13.929320987654322. Std of Reward: 7.686170130002151.\n",
      "Step: 1750000. Mean Reward: 13.451840490797549. Std of Reward: 8.389211026268708.\n",
      "Saved Model\n",
      "Step: 1760000. Mean Reward: 13.728353658536587. Std of Reward: 8.402212127233113.\n",
      "Step: 1770000. Mean Reward: 13.846625766871165. Std of Reward: 8.26463960228485.\n",
      "Step: 1780000. Mean Reward: 14.134049079754604. Std of Reward: 8.07763842349103.\n",
      "Step: 1790000. Mean Reward: 14.47852564102564. Std of Reward: 8.44259293051419.\n",
      "Step: 1800000. Mean Reward: 13.810828025477706. Std of Reward: 8.115608376109199.\n",
      "Saved Model\n",
      "Step: 1810000. Mean Reward: 14.053105590062113. Std of Reward: 7.681561551588213.\n",
      "Step: 1820000. Mean Reward: 13.796273291925464. Std of Reward: 8.322827534037717.\n",
      "Step: 1830000. Mean Reward: 13.129393939393939. Std of Reward: 8.07859496462024.\n",
      "Step: 1840000. Mean Reward: 12.700882352941175. Std of Reward: 8.051089574653876.\n",
      "Step: 1850000. Mean Reward: 14.334177215189875. Std of Reward: 8.19622112797851.\n",
      "Saved Model\n",
      "Step: 1860000. Mean Reward: 14.2375. Std of Reward: 8.127224695429554.\n",
      "Step: 1870000. Mean Reward: 15.015937500000001. Std of Reward: 7.561289927723559.\n",
      "Step: 1880000. Mean Reward: 15.081012658227849. Std of Reward: 7.880547287898334.\n",
      "Step: 1890000. Mean Reward: 14.032208588957054. Std of Reward: 8.52311127446905.\n",
      "Step: 1900000. Mean Reward: 15.226129032258065. Std of Reward: 8.05170856539532.\n",
      "Saved Model\n",
      "Step: 1910000. Mean Reward: 14.907911392405062. Std of Reward: 8.184955561055446.\n",
      "Step: 1920000. Mean Reward: 15.014423076923077. Std of Reward: 8.414292651257497.\n",
      "Step: 1930000. Mean Reward: 13.52251461988304. Std of Reward: 8.529357907150208.\n",
      "Step: 1940000. Mean Reward: 14.68944099378882. Std of Reward: 7.8098588155336035.\n",
      "Step: 1950000. Mean Reward: 14.550974025974025. Std of Reward: 7.9810662121324505.\n",
      "Saved Model\n",
      "Step: 1960000. Mean Reward: 14.137116564417175. Std of Reward: 8.188158420033538.\n",
      "Step: 1970000. Mean Reward: 14.35290322580645. Std of Reward: 8.317378306525473.\n",
      "Step: 1980000. Mean Reward: 15.454716981132076. Std of Reward: 7.849898433931803.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1990000. Mean Reward: 15.202173913043477. Std of Reward: 7.916072469895424.\n",
      "Step: 2000000. Mean Reward: 16.13344370860927. Std of Reward: 8.007163022197675.\n",
      "Saved Model\n",
      "Step: 2010000. Mean Reward: 13.610606060606061. Std of Reward: 8.230372037466763.\n",
      "Step: 2020000. Mean Reward: 15.514423076923077. Std of Reward: 8.316376355889672.\n",
      "Step: 2030000. Mean Reward: 14.662578616352201. Std of Reward: 8.294957490296865.\n",
      "Step: 2040000. Mean Reward: 14.016666666666666. Std of Reward: 8.29434211442421.\n",
      "Step: 2050000. Mean Reward: 13.867592592592594. Std of Reward: 8.36277479244066.\n",
      "Saved Model\n",
      "Step: 2060000. Mean Reward: 14.164779874213835. Std of Reward: 8.00847929851948.\n",
      "Step: 2070000. Mean Reward: 15.664814814814815. Std of Reward: 7.978528069192438.\n",
      "Step: 2080000. Mean Reward: 14.374844720496897. Std of Reward: 8.32007996151181.\n",
      "Step: 2090000. Mean Reward: 14.485000000000003. Std of Reward: 8.224053516970814.\n",
      "Step: 2100000. Mean Reward: 15.325471698113208. Std of Reward: 8.048498566814596.\n",
      "Saved Model\n",
      "Step: 2110000. Mean Reward: 14.068553459119501. Std of Reward: 8.051453155022358.\n",
      "Step: 2120000. Mean Reward: 14.739263803680982. Std of Reward: 8.20796923527479.\n",
      "Step: 2130000. Mean Reward: 14.995962732919255. Std of Reward: 7.834457603210279.\n",
      "Step: 2140000. Mean Reward: 14.709935897435898. Std of Reward: 8.250894318022315.\n",
      "Step: 2150000. Mean Reward: 14.892356687898092. Std of Reward: 7.88421418402147.\n",
      "Saved Model\n",
      "Step: 2160000. Mean Reward: 16.391935483870967. Std of Reward: 7.7904624979086785.\n",
      "Step: 2170000. Mean Reward: 14.522049689440994. Std of Reward: 8.387133085198737.\n",
      "Step: 2180000. Mean Reward: 15.517197452229299. Std of Reward: 8.111587829388206.\n",
      "Step: 2190000. Mean Reward: 14.016149068322981. Std of Reward: 8.75913472158902.\n",
      "Step: 2200000. Mean Reward: 14.870253164556962. Std of Reward: 7.854310350065639.\n",
      "Saved Model\n",
      "Step: 2210000. Mean Reward: 15.442405063291142. Std of Reward: 8.202114919481403.\n",
      "Step: 2220000. Mean Reward: 17.142857142857142. Std of Reward: 7.7147195043980625.\n",
      "Step: 2230000. Mean Reward: 14.451886792452832. Std of Reward: 8.050838635156117.\n",
      "Step: 2240000. Mean Reward: 16.240322580645163. Std of Reward: 7.5638915073295045.\n",
      "Step: 2250000. Mean Reward: 15.725320512820517. Std of Reward: 7.848780112619149.\n",
      "Saved Model\n",
      "Step: 2260000. Mean Reward: 16.003821656050953. Std of Reward: 7.343536829460697.\n",
      "Step: 2270000. Mean Reward: 15.686075949367089. Std of Reward: 7.972333238146437.\n",
      "Step: 2280000. Mean Reward: 15.265723270440251. Std of Reward: 8.105233844365529.\n",
      "Step: 2290000. Mean Reward: 15.690384615384614. Std of Reward: 8.255586910491973.\n",
      "Step: 2300000. Mean Reward: 14.985668789808914. Std of Reward: 8.377650832418215.\n",
      "Saved Model\n",
      "Step: 2310000. Mean Reward: 14.974367088607593. Std of Reward: 7.722310144413507.\n",
      "Step: 2320000. Mean Reward: 13.855279503105589. Std of Reward: 8.048493556210534.\n",
      "Step: 2330000. Mean Reward: 14.2578125. Std of Reward: 8.535804273168624.\n",
      "Step: 2340000. Mean Reward: 15.01474358974359. Std of Reward: 8.30657605174867.\n",
      "Step: 2350000. Mean Reward: 15.443124999999998. Std of Reward: 7.7476195688982425.\n",
      "Saved Model\n",
      "Step: 2360000. Mean Reward: 16.12721518987342. Std of Reward: 7.480167015110457.\n",
      "Step: 2370000. Mean Reward: 15.862341772151899. Std of Reward: 8.31034639316142.\n",
      "Step: 2380000. Mean Reward: 14.4871875. Std of Reward: 8.582974147394582.\n",
      "Step: 2390000. Mean Reward: 14.533024691358026. Std of Reward: 7.912582111173128.\n",
      "Step: 2400000. Mean Reward: 15.185256410256411. Std of Reward: 7.958498557719799.\n",
      "Saved Model\n",
      "Step: 2410000. Mean Reward: 16.4312101910828. Std of Reward: 7.639109925002098.\n",
      "Step: 2420000. Mean Reward: 16.730645161290322. Std of Reward: 7.943959740454408.\n",
      "Step: 2430000. Mean Reward: 15.82677419354839. Std of Reward: 8.369786827013971.\n",
      "Step: 2440000. Mean Reward: 15.604220779220778. Std of Reward: 7.981567546335186.\n",
      "Step: 2450000. Mean Reward: 15.347452229299364. Std of Reward: 8.143902404566651.\n",
      "Saved Model\n",
      "Step: 2460000. Mean Reward: 15.51516129032258. Std of Reward: 8.340018902650407.\n",
      "Step: 2470000. Mean Reward: 15.58741935483871. Std of Reward: 8.720819718700588.\n",
      "Step: 2480000. Mean Reward: 15.056050955414014. Std of Reward: 7.909756432749937.\n",
      "Step: 2490000. Mean Reward: 14.646794871794876. Std of Reward: 8.24732800453169.\n",
      "Step: 2500000. Mean Reward: 15.38679245283019. Std of Reward: 7.4552848437587045.\n",
      "Saved Model\n",
      "Step: 2510000. Mean Reward: 15.640064102564105. Std of Reward: 8.390080032074115.\n",
      "Step: 2520000. Mean Reward: 15.658653846153843. Std of Reward: 8.255377352922872.\n",
      "Step: 2530000. Mean Reward: 15.58993710691824. Std of Reward: 7.962381639917309.\n",
      "Step: 2540000. Mean Reward: 13.936562499999999. Std of Reward: 8.481005840028278.\n",
      "Step: 2550000. Mean Reward: 15.834615384615386. Std of Reward: 7.644793802841803.\n",
      "Saved Model\n",
      "Step: 2560000. Mean Reward: 16.491935483870968. Std of Reward: 7.917325802744599.\n",
      "Step: 2570000. Mean Reward: 16.035294117647055. Std of Reward: 8.389224107308442.\n",
      "Step: 2580000. Mean Reward: 15.706211180124223. Std of Reward: 8.094008515167358.\n",
      "Step: 2590000. Mean Reward: 17.025641025641026. Std of Reward: 7.829451071196856.\n",
      "Step: 2600000. Mean Reward: 15.044620253164556. Std of Reward: 8.350152703528723.\n",
      "Saved Model\n",
      "Step: 2610000. Mean Reward: 16.54455128205128. Std of Reward: 7.757276513133736.\n",
      "Step: 2620000. Mean Reward: 16.17101910828026. Std of Reward: 7.65240715508204.\n",
      "Step: 2630000. Mean Reward: 14.746202531645567. Std of Reward: 8.443030502150679.\n",
      "Step: 2640000. Mean Reward: 13.950925925925928. Std of Reward: 8.265898396614551.\n",
      "Step: 2650000. Mean Reward: 16.056962025316455. Std of Reward: 8.196882064592389.\n",
      "Saved Model\n",
      "Step: 2660000. Mean Reward: 15.981730769230767. Std of Reward: 7.6593731051184735.\n",
      "Step: 2670000. Mean Reward: 15.0346875. Std of Reward: 8.12856459667657.\n",
      "Step: 2680000. Mean Reward: 15.052830188679247. Std of Reward: 8.753950133135799.\n",
      "Step: 2690000. Mean Reward: 15.5290625. Std of Reward: 7.417221244920077.\n",
      "Step: 2700000. Mean Reward: 15.379617834394903. Std of Reward: 8.326467574808154.\n",
      "Saved Model\n",
      "Step: 2710000. Mean Reward: 16.10377358490566. Std of Reward: 8.119017482402276.\n",
      "Step: 2720000. Mean Reward: 16.099019607843136. Std of Reward: 8.175586306628524.\n",
      "Step: 2730000. Mean Reward: 15.278846153846153. Std of Reward: 8.071030894147293.\n",
      "Step: 2740000. Mean Reward: 15.925632911392405. Std of Reward: 8.176797865521708.\n",
      "Step: 2750000. Mean Reward: 15.241509433962264. Std of Reward: 7.919644009904844.\n",
      "Saved Model\n",
      "Step: 2760000. Mean Reward: 16.167405063291138. Std of Reward: 7.341056142791711.\n",
      "Step: 2770000. Mean Reward: 15.47173913043478. Std of Reward: 8.375555571836175.\n",
      "Step: 2780000. Mean Reward: 15.428246753246752. Std of Reward: 8.430699015334659.\n",
      "Step: 2790000. Mean Reward: 15.568789808917199. Std of Reward: 8.029641372667529.\n",
      "Step: 2800000. Mean Reward: 16.16331168831169. Std of Reward: 8.117313631440027.\n",
      "Saved Model\n",
      "Step: 2810000. Mean Reward: 16.357371794871796. Std of Reward: 7.289113775418747.\n",
      "Step: 2820000. Mean Reward: 17.28717948717949. Std of Reward: 7.668796816242427.\n",
      "Step: 2830000. Mean Reward: 17.526143790849673. Std of Reward: 7.348734017883536.\n",
      "Step: 2840000. Mean Reward: 16.414150943396223. Std of Reward: 7.777693737644029.\n",
      "Step: 2850000. Mean Reward: 16.210126582278484. Std of Reward: 7.985165755065806.\n",
      "Saved Model\n",
      "Step: 2860000. Mean Reward: 15.991139240506328. Std of Reward: 8.125215710841202.\n",
      "Step: 2870000. Mean Reward: 16.275806451612905. Std of Reward: 7.839219749765895.\n",
      "Step: 2880000. Mean Reward: 16.30534591194968. Std of Reward: 7.993729050050917.\n",
      "Step: 2890000. Mean Reward: 16.77516339869281. Std of Reward: 7.932353136395934.\n",
      "Step: 2900000. Mean Reward: 16.495541401273886. Std of Reward: 7.708028686736127.\n",
      "Saved Model\n",
      "Step: 2910000. Mean Reward: 15.306645569620253. Std of Reward: 7.917817802134425.\n",
      "Step: 2920000. Mean Reward: 15.042307692307695. Std of Reward: 8.009621925690682.\n",
      "Step: 2930000. Mean Reward: 15.147115384615384. Std of Reward: 7.879658248610248.\n",
      "Step: 2940000. Mean Reward: 16.479545454545455. Std of Reward: 7.2865772647345795.\n",
      "Step: 2950000. Mean Reward: 17.54208860759494. Std of Reward: 6.974164625243428.\n",
      "Saved Model\n",
      "Step: 2960000. Mean Reward: 16.80576923076923. Std of Reward: 7.78774711823097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2970000. Mean Reward: 14.897756410256411. Std of Reward: 8.08877891435286.\n",
      "Step: 2980000. Mean Reward: 17.40286624203822. Std of Reward: 7.373619361296968.\n",
      "Step: 2990000. Mean Reward: 16.004605263157895. Std of Reward: 8.054763945181998.\n",
      "Step: 3000000. Mean Reward: 16.54070512820513. Std of Reward: 7.892947201675382.\n",
      "Saved Model\n",
      "Step: 3010000. Mean Reward: 16.56045751633987. Std of Reward: 8.02699622636823.\n",
      "Step: 3020000. Mean Reward: 16.405228758169933. Std of Reward: 8.071946018734828.\n",
      "Step: 3030000. Mean Reward: 16.494444444444444. Std of Reward: 7.663397759103584.\n",
      "Step: 3040000. Mean Reward: 16.972115384615382. Std of Reward: 7.282073705217822.\n",
      "Step: 3050000. Mean Reward: 15.833333333333334. Std of Reward: 7.5909724836718535.\n",
      "Saved Model\n",
      "Step: 3060000. Mean Reward: 16.736274509803923. Std of Reward: 6.998882346102055.\n",
      "Step: 3070000. Mean Reward: 16.16955128205128. Std of Reward: 7.435544773633166.\n",
      "Step: 3080000. Mean Reward: 17.35. Std of Reward: 6.859229255100456.\n",
      "Step: 3090000. Mean Reward: 17.132903225806448. Std of Reward: 7.568997544546069.\n",
      "Step: 3100000. Mean Reward: 15.010126582278481. Std of Reward: 8.51425230945385.\n",
      "Saved Model\n",
      "Step: 3110000. Mean Reward: 17.608064516129033. Std of Reward: 6.613811267318461.\n",
      "Step: 3120000. Mean Reward: 16.23774193548387. Std of Reward: 7.445692285531417.\n",
      "Step: 3130000. Mean Reward: 16.487987012987013. Std of Reward: 7.8714366400964.\n",
      "Step: 3140000. Mean Reward: 16.67171052631579. Std of Reward: 7.473205802655014.\n",
      "Step: 3150000. Mean Reward: 16.56075949367089. Std of Reward: 7.35940013243235.\n",
      "Saved Model\n",
      "Step: 3160000. Mean Reward: 16.469108280254776. Std of Reward: 7.622125719162682.\n",
      "Step: 3170000. Mean Reward: 17.83474025974026. Std of Reward: 6.9325257478225994.\n",
      "Step: 3180000. Mean Reward: 16.425632911392405. Std of Reward: 7.593353058785857.\n",
      "Step: 3190000. Mean Reward: 16.744805194805192. Std of Reward: 7.209693530671521.\n",
      "Step: 3200000. Mean Reward: 17.23333333333333. Std of Reward: 7.508899278593924.\n",
      "Saved Model\n",
      "Step: 3210000. Mean Reward: 17.010526315789473. Std of Reward: 7.635660433080262.\n",
      "Step: 3220000. Mean Reward: 16.290522875816993. Std of Reward: 7.73192759289456.\n",
      "Step: 3230000. Mean Reward: 17.47798742138365. Std of Reward: 7.781732744253457.\n",
      "Step: 3240000. Mean Reward: 17.93921568627451. Std of Reward: 7.10432976047961.\n",
      "Step: 3250000. Mean Reward: 17.268387096774195. Std of Reward: 6.826615416420092.\n",
      "Saved Model\n",
      "Step: 3260000. Mean Reward: 17.82694805194805. Std of Reward: 6.676213185915718.\n",
      "Step: 3270000. Mean Reward: 16.885126582278485. Std of Reward: 7.605680566702174.\n",
      "Step: 3280000. Mean Reward: 16.03766233766234. Std of Reward: 7.683899746519054.\n",
      "Step: 3290000. Mean Reward: 18.803571428571427. Std of Reward: 5.749325502909401.\n",
      "Step: 3300000. Mean Reward: 17.132051282051286. Std of Reward: 7.3744511936568236.\n",
      "Saved Model\n",
      "Step: 3310000. Mean Reward: 17.045098039215684. Std of Reward: 7.565707300125522.\n",
      "Step: 3320000. Mean Reward: 17.002258064516127. Std of Reward: 7.769116572719158.\n",
      "Step: 3330000. Mean Reward: 16.58888888888889. Std of Reward: 7.441796426908608.\n",
      "Step: 3340000. Mean Reward: 17.380194805194808. Std of Reward: 7.699151198854985.\n",
      "Step: 3350000. Mean Reward: 16.926470588235293. Std of Reward: 7.458889636003211.\n",
      "Saved Model\n",
      "Step: 3360000. Mean Reward: 17.708223684210527. Std of Reward: 6.7109774664521495.\n",
      "Step: 3370000. Mean Reward: 17.620588235294118. Std of Reward: 7.28519299050349.\n",
      "Step: 3380000. Mean Reward: 18.14025974025974. Std of Reward: 6.943445189627853.\n",
      "Step: 3390000. Mean Reward: 17.501633986928105. Std of Reward: 7.624218417674923.\n",
      "Step: 3400000. Mean Reward: 18.115789473684213. Std of Reward: 6.821662527558013.\n",
      "Saved Model\n",
      "Step: 3410000. Mean Reward: 17.46602564102564. Std of Reward: 6.832874407305406.\n",
      "Step: 3420000. Mean Reward: 17.093464052287583. Std of Reward: 7.0055339768639575.\n",
      "Step: 3430000. Mean Reward: 17.048692810457514. Std of Reward: 7.373876224811289.\n",
      "Step: 3440000. Mean Reward: 17.442628205128205. Std of Reward: 7.039635508500266.\n",
      "Step: 3450000. Mean Reward: 18.097712418300652. Std of Reward: 7.205116509626805.\n",
      "Saved Model\n",
      "Step: 3460000. Mean Reward: 18.152272727272727. Std of Reward: 6.6756422447705575.\n",
      "Step: 3470000. Mean Reward: 16.170394736842102. Std of Reward: 7.685211694647795.\n",
      "Step: 3480000. Mean Reward: 18.087500000000002. Std of Reward: 6.569243177831612.\n",
      "Step: 3490000. Mean Reward: 17.919000000000004. Std of Reward: 7.11816144333165.\n",
      "Step: 3500000. Mean Reward: 18.411858974358974. Std of Reward: 6.743522799645785.\n",
      "Saved Model\n",
      "Step: 3510000. Mean Reward: 18.000653594771244. Std of Reward: 7.089647674460084.\n",
      "Step: 3520000. Mean Reward: 18.2224025974026. Std of Reward: 6.5274720206809365.\n",
      "Step: 3530000. Mean Reward: 18.357894736842102. Std of Reward: 6.694806277569413.\n",
      "Step: 3540000. Mean Reward: 17.622875816993464. Std of Reward: 7.339168772117475.\n",
      "Step: 3550000. Mean Reward: 18.18496732026144. Std of Reward: 7.40479460679813.\n",
      "Saved Model\n",
      "Step: 3560000. Mean Reward: 17.783116883116882. Std of Reward: 7.0562471648372265.\n",
      "Step: 3570000. Mean Reward: 17.860645161290325. Std of Reward: 6.878838487608617.\n",
      "Step: 3580000. Mean Reward: 17.887254901960784. Std of Reward: 7.351518293700063.\n",
      "Step: 3590000. Mean Reward: 18.266666666666666. Std of Reward: 6.701792463380391.\n",
      "Step: 3600000. Mean Reward: 16.978846153846153. Std of Reward: 7.315064011281915.\n",
      "Saved Model\n",
      "Step: 3610000. Mean Reward: 17.04019607843137. Std of Reward: 7.261686679112885.\n",
      "Step: 3620000. Mean Reward: 17.706209150326796. Std of Reward: 6.714135708279756.\n",
      "Step: 3630000. Mean Reward: 17.622402597402598. Std of Reward: 6.669147909434557.\n",
      "Step: 3640000. Mean Reward: 16.308496732026146. Std of Reward: 7.544061835776232.\n",
      "Step: 3650000. Mean Reward: 17.884516129032257. Std of Reward: 6.886725350715785.\n",
      "Saved Model\n",
      "Step: 3660000. Mean Reward: 17.801307189542484. Std of Reward: 6.89101183012259.\n",
      "Step: 3670000. Mean Reward: 19.168954248366013. Std of Reward: 6.435707695889116.\n",
      "Step: 3680000. Mean Reward: 17.869281045751634. Std of Reward: 6.674686656822544.\n",
      "Step: 3690000. Mean Reward: 18.294444444444444. Std of Reward: 6.6254992549718486.\n",
      "Step: 3700000. Mean Reward: 19.19415584415584. Std of Reward: 6.407772137640381.\n",
      "Saved Model\n",
      "Step: 3710000. Mean Reward: 18.42745098039216. Std of Reward: 6.802058851083997.\n",
      "Step: 3720000. Mean Reward: 18.63474025974026. Std of Reward: 7.032709588296265.\n",
      "Step: 3730000. Mean Reward: 18.008552631578947. Std of Reward: 7.228142588075148.\n",
      "Step: 3740000. Mean Reward: 18.0. Std of Reward: 6.695747326330685.\n",
      "Step: 3750000. Mean Reward: 18.36078431372549. Std of Reward: 6.065591752370135.\n",
      "Saved Model\n",
      "Step: 3760000. Mean Reward: 19.173870967741934. Std of Reward: 6.202632987961699.\n",
      "Step: 3770000. Mean Reward: 17.254276315789472. Std of Reward: 6.710981142674578.\n",
      "Step: 3780000. Mean Reward: 17.879934210526315. Std of Reward: 6.54971438677316.\n",
      "Step: 3790000. Mean Reward: 18.196103896103896. Std of Reward: 6.672125414562226.\n",
      "Step: 3800000. Mean Reward: 18.241776315789473. Std of Reward: 6.7832452354053645.\n",
      "Saved Model\n",
      "Step: 3810000. Mean Reward: 18.598692810457518. Std of Reward: 6.600217731881954.\n",
      "Step: 3820000. Mean Reward: 18.730718954248367. Std of Reward: 6.197039995987033.\n",
      "Step: 3830000. Mean Reward: 18.21535947712418. Std of Reward: 6.663992799679099.\n",
      "Step: 3840000. Mean Reward: 18.43267973856209. Std of Reward: 6.479137763031017.\n",
      "Step: 3850000. Mean Reward: 18.201290322580643. Std of Reward: 6.542715595784804.\n",
      "Saved Model\n",
      "Step: 3860000. Mean Reward: 18.28848684210526. Std of Reward: 6.608003197864296.\n",
      "Step: 3870000. Mean Reward: 19.045394736842102. Std of Reward: 6.222165268912142.\n",
      "Step: 3880000. Mean Reward: 18.591176470588234. Std of Reward: 6.504181956990628.\n",
      "Step: 3890000. Mean Reward: 18.628104575163402. Std of Reward: 6.677392915347035.\n",
      "Step: 3900000. Mean Reward: 18.97549019607843. Std of Reward: 5.784575268264525.\n",
      "Saved Model\n",
      "Step: 3910000. Mean Reward: 18.2078431372549. Std of Reward: 6.841836215441253.\n",
      "Step: 3920000. Mean Reward: 18.308823529411764. Std of Reward: 6.289962741992635.\n",
      "Step: 3930000. Mean Reward: 18.38888888888889. Std of Reward: 7.174367094725257.\n",
      "Step: 3940000. Mean Reward: 17.214666666666666. Std of Reward: 6.956777382923471.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3950000. Mean Reward: 17.56078431372549. Std of Reward: 7.115404767528478.\n",
      "Saved Model\n",
      "Step: 3960000. Mean Reward: 18.640064102564104. Std of Reward: 6.8414845533207735.\n",
      "Step: 3970000. Mean Reward: 17.970129870129867. Std of Reward: 6.471938727477621.\n",
      "Step: 3980000. Mean Reward: 17.986513157894734. Std of Reward: 7.165386394608276.\n",
      "Step: 3990000. Mean Reward: 19.476797385620912. Std of Reward: 6.465246524230775.\n",
      "Step: 4000000. Mean Reward: 17.204248366013072. Std of Reward: 6.992563621710839.\n",
      "Saved Model\n",
      "Step: 4010000. Mean Reward: 18.922903225806454. Std of Reward: 6.363796895416966.\n",
      "Step: 4020000. Mean Reward: 17.916666666666668. Std of Reward: 7.151664644650396.\n",
      "Step: 4030000. Mean Reward: 19.03774834437086. Std of Reward: 6.280849604252515.\n",
      "Step: 4040000. Mean Reward: 18.096794871794874. Std of Reward: 6.559507387224334.\n",
      "Step: 4050000. Mean Reward: 19.00718954248366. Std of Reward: 6.068512481268821.\n",
      "Saved Model\n",
      "Step: 4060000. Mean Reward: 17.59383116883117. Std of Reward: 7.597336614487586.\n",
      "Step: 4070000. Mean Reward: 18.506907894736845. Std of Reward: 6.614798623814778.\n",
      "Step: 4080000. Mean Reward: 18.483006535947712. Std of Reward: 6.259991134175612.\n",
      "Step: 4090000. Mean Reward: 18.07450980392157. Std of Reward: 6.812212979255748.\n",
      "Step: 4100000. Mean Reward: 17.369934640522875. Std of Reward: 7.3451983779483045.\n",
      "Saved Model\n",
      "Step: 4110000. Mean Reward: 18.554901960784314. Std of Reward: 6.268824630286788.\n",
      "Step: 4120000. Mean Reward: 18.39313725490196. Std of Reward: 6.745642647872407.\n",
      "Step: 4130000. Mean Reward: 18.85751633986928. Std of Reward: 6.683754500547519.\n",
      "Step: 4140000. Mean Reward: 18.9859477124183. Std of Reward: 5.908201504423647.\n",
      "Step: 4150000. Mean Reward: 17.950326797385618. Std of Reward: 7.210306024372258.\n",
      "Saved Model\n",
      "Step: 4160000. Mean Reward: 18.48267973856209. Std of Reward: 6.419120539861807.\n",
      "Step: 4170000. Mean Reward: 17.683986928104574. Std of Reward: 7.52746312497566.\n",
      "Step: 4180000. Mean Reward: 17.98169934640523. Std of Reward: 6.730269521436421.\n",
      "Step: 4190000. Mean Reward: 17.932051282051283. Std of Reward: 6.930730871100576.\n",
      "Step: 4200000. Mean Reward: 17.91298701298701. Std of Reward: 7.074744282457776.\n",
      "Saved Model\n",
      "Step: 4210000. Mean Reward: 18.931907894736838. Std of Reward: 6.243943247739388.\n",
      "Step: 4220000. Mean Reward: 18.776143790849673. Std of Reward: 6.46574959377407.\n",
      "Step: 4230000. Mean Reward: 18.007843137254902. Std of Reward: 7.081682893412063.\n",
      "Step: 4240000. Mean Reward: 18.030333333333335. Std of Reward: 6.989537172723876.\n",
      "Step: 4250000. Mean Reward: 18.216987179487177. Std of Reward: 6.607378589149288.\n",
      "Saved Model\n",
      "Step: 4260000. Mean Reward: 18.62727272727273. Std of Reward: 6.635875271125243.\n",
      "Step: 4270000. Mean Reward: 17.73782894736842. Std of Reward: 7.187701934715986.\n",
      "Step: 4280000. Mean Reward: 17.890849673202617. Std of Reward: 6.943427884073069.\n",
      "Step: 4290000. Mean Reward: 18.417333333333332. Std of Reward: 7.397745121919846.\n",
      "Step: 4300000. Mean Reward: 18.24455128205128. Std of Reward: 6.895538258582521.\n",
      "Saved Model\n",
      "Step: 4310000. Mean Reward: 17.372402597402594. Std of Reward: 7.522442703505671.\n",
      "Step: 4320000. Mean Reward: 17.81480263157895. Std of Reward: 6.72446397495885.\n",
      "Step: 4330000. Mean Reward: 17.563725490196077. Std of Reward: 7.177748466533734.\n",
      "Step: 4340000. Mean Reward: 18.17156862745098. Std of Reward: 6.752457225718616.\n",
      "Step: 4350000. Mean Reward: 17.787337662337663. Std of Reward: 6.921009708091055.\n",
      "Saved Model\n",
      "Step: 4360000. Mean Reward: 17.80490196078431. Std of Reward: 6.992955756984773.\n",
      "Step: 4370000. Mean Reward: 17.504934210526315. Std of Reward: 7.238363528769407.\n",
      "Step: 4380000. Mean Reward: 18.47077922077922. Std of Reward: 6.73792257981021.\n",
      "Step: 4390000. Mean Reward: 17.409032258064517. Std of Reward: 7.783395210251077.\n",
      "Step: 4400000. Mean Reward: 17.843181818181822. Std of Reward: 7.05267304069104.\n",
      "Saved Model\n",
      "Step: 4410000. Mean Reward: 17.16611842105263. Std of Reward: 7.483223785429549.\n",
      "Step: 4420000. Mean Reward: 18.593464052287583. Std of Reward: 6.173392444584383.\n",
      "Step: 4430000. Mean Reward: 17.80224358974359. Std of Reward: 7.463426515409691.\n",
      "Step: 4440000. Mean Reward: 17.51209150326797. Std of Reward: 7.0771819336757265.\n",
      "Step: 4450000. Mean Reward: 18.42101910828025. Std of Reward: 6.4126545061247056.\n",
      "Saved Model\n",
      "Step: 4460000. Mean Reward: 18.07861842105263. Std of Reward: 6.813933581595692.\n",
      "Step: 4470000. Mean Reward: 18.43300653594771. Std of Reward: 6.545307562785766.\n",
      "Step: 4480000. Mean Reward: 18.812745098039212. Std of Reward: 6.207971181467174.\n",
      "Step: 4490000. Mean Reward: 18.086363636363636. Std of Reward: 6.38855834175054.\n",
      "Step: 4500000. Mean Reward: 18.16151315789474. Std of Reward: 7.119119157506372.\n",
      "Saved Model\n",
      "Step: 4510000. Mean Reward: 18.60357142857143. Std of Reward: 6.484637457806231.\n",
      "Step: 4520000. Mean Reward: 18.43921568627451. Std of Reward: 6.531834915145068.\n",
      "Step: 4530000. Mean Reward: 18.16151315789474. Std of Reward: 6.748170976356679.\n",
      "Step: 4540000. Mean Reward: 18.415359477124184. Std of Reward: 6.573255580232962.\n",
      "Step: 4550000. Mean Reward: 18.95032679738562. Std of Reward: 6.2762351249920405.\n",
      "Saved Model\n",
      "Step: 4560000. Mean Reward: 17.796405228758168. Std of Reward: 7.03391203031206.\n",
      "Step: 4570000. Mean Reward: 17.627000000000002. Std of Reward: 7.157636085561583.\n",
      "Step: 4580000. Mean Reward: 18.118954248366013. Std of Reward: 6.983898396662157.\n",
      "Step: 4590000. Mean Reward: 18.791666666666668. Std of Reward: 6.22853193318739.\n",
      "Step: 4600000. Mean Reward: 18.253311258278146. Std of Reward: 5.644315750721851.\n",
      "Saved Model\n",
      "Step: 4610000. Mean Reward: 17.665131578947367. Std of Reward: 6.948336225203588.\n",
      "Step: 4620000. Mean Reward: 17.545424836601306. Std of Reward: 7.46163906251518.\n",
      "Step: 4630000. Mean Reward: 17.76516129032258. Std of Reward: 7.472671444829655.\n",
      "Step: 4640000. Mean Reward: 18.19569536423841. Std of Reward: 6.745599351368551.\n",
      "Step: 4650000. Mean Reward: 18.288636363636364. Std of Reward: 6.786406205014322.\n",
      "Saved Model\n",
      "Step: 4660000. Mean Reward: 17.832026143790852. Std of Reward: 6.936496766957316.\n",
      "Step: 4670000. Mean Reward: 17.667532467532467. Std of Reward: 6.70897957205837.\n",
      "Step: 4680000. Mean Reward: 17.70263157894737. Std of Reward: 6.965959972462527.\n",
      "Step: 4690000. Mean Reward: 18.138235294117646. Std of Reward: 7.304497148001329.\n",
      "Step: 4700000. Mean Reward: 16.95888157894737. Std of Reward: 7.544580448498855.\n",
      "Saved Model\n",
      "Step: 4710000. Mean Reward: 18.358169934640525. Std of Reward: 6.692553801757805.\n",
      "Step: 4720000. Mean Reward: 17.308169934640524. Std of Reward: 7.392662095619622.\n",
      "Step: 4730000. Mean Reward: 17.443870967741937. Std of Reward: 8.05590814144195.\n",
      "Step: 4740000. Mean Reward: 18.18708609271523. Std of Reward: 7.166557874882822.\n",
      "Step: 4750000. Mean Reward: 17.77305194805195. Std of Reward: 6.849014369124233.\n",
      "Saved Model\n",
      "Step: 4760000. Mean Reward: 17.152547770700636. Std of Reward: 7.816285864722166.\n",
      "Step: 4770000. Mean Reward: 18.680132450331126. Std of Reward: 6.872741241156062.\n",
      "Step: 4780000. Mean Reward: 17.485947712418298. Std of Reward: 7.286260365572525.\n",
      "Step: 4790000. Mean Reward: 17.92077922077922. Std of Reward: 6.5057060401717095.\n",
      "Step: 4800000. Mean Reward: 17.890849673202613. Std of Reward: 6.980309462558814.\n",
      "Saved Model\n",
      "Step: 4810000. Mean Reward: 17.603896103896105. Std of Reward: 7.249772796411982.\n",
      "Step: 4820000. Mean Reward: 17.119155844155845. Std of Reward: 7.594838041184058.\n",
      "Step: 4830000. Mean Reward: 18.285294117647055. Std of Reward: 7.078208947675877.\n",
      "Step: 4840000. Mean Reward: 17.71535947712418. Std of Reward: 7.070749562852591.\n",
      "Step: 4850000. Mean Reward: 18.1281045751634. Std of Reward: 6.772599133400985.\n",
      "Saved Model\n",
      "Step: 4860000. Mean Reward: 17.201290322580643. Std of Reward: 7.252730183128363.\n",
      "Step: 4870000. Mean Reward: 18.01677631578947. Std of Reward: 7.143535318363185.\n",
      "Step: 4880000. Mean Reward: 16.77741935483871. Std of Reward: 7.81558243665445.\n",
      "Step: 4890000. Mean Reward: 16.924679487179485. Std of Reward: 7.572264033271636.\n",
      "Step: 4900000. Mean Reward: 18.03668831168831. Std of Reward: 6.958373546263803.\n",
      "Saved Model\n",
      "Step: 4910000. Mean Reward: 17.586842105263155. Std of Reward: 7.571809161294891.\n",
      "Step: 4920000. Mean Reward: 17.712179487179487. Std of Reward: 7.392692536697527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4930000. Mean Reward: 17.91348684210526. Std of Reward: 7.076141274870939.\n",
      "Step: 4940000. Mean Reward: 17.104545454545455. Std of Reward: 7.035636015602128.\n",
      "Step: 4950000. Mean Reward: 17.684313725490195. Std of Reward: 7.262949828774931.\n",
      "Saved Model\n",
      "Step: 4960000. Mean Reward: 17.42581699346405. Std of Reward: 7.287089273787968.\n",
      "Step: 4970000. Mean Reward: 17.947058823529414. Std of Reward: 7.434184500845954.\n",
      "Step: 4980000. Mean Reward: 18.21797385620915. Std of Reward: 7.216085006625539.\n",
      "Step: 4990000. Mean Reward: 17.433774834437084. Std of Reward: 6.915304913162954.\n",
      "Step: 5000000. Mean Reward: 18.001612903225805. Std of Reward: 7.294997002707467.\n",
      "Saved Model\n",
      "Step: 5010000. Mean Reward: 17.829807692307693. Std of Reward: 6.848705611483189.\n",
      "Step: 5020000. Mean Reward: 18.161858974358974. Std of Reward: 7.314722404295779.\n",
      "Step: 5030000. Mean Reward: 18.45686274509804. Std of Reward: 6.805483800985408.\n",
      "Step: 5040000. Mean Reward: 18.366993464052285. Std of Reward: 7.185140720256765.\n",
      "Step: 5050000. Mean Reward: 17.44545454545455. Std of Reward: 7.723131816376611.\n",
      "Saved Model\n",
      "Step: 5060000. Mean Reward: 17.134967320261435. Std of Reward: 7.265816835014339.\n",
      "Step: 5070000. Mean Reward: 17.148692810457515. Std of Reward: 7.602931898593738.\n",
      "Step: 5080000. Mean Reward: 16.743987341772154. Std of Reward: 7.504986438553885.\n",
      "Step: 5090000. Mean Reward: 17.54967320261438. Std of Reward: 7.082285958855896.\n",
      "Step: 5100000. Mean Reward: 18.139285714285712. Std of Reward: 6.74061147050395.\n",
      "Saved Model\n",
      "Step: 5110000. Mean Reward: 17.5140522875817. Std of Reward: 7.392604628059618.\n",
      "Step: 5120000. Mean Reward: 17.477124183006534. Std of Reward: 7.729975156019789.\n",
      "Step: 5130000. Mean Reward: 17.259999999999998. Std of Reward: 7.366864348050711.\n",
      "Step: 5140000. Mean Reward: 18.08986928104575. Std of Reward: 7.013745513397489.\n",
      "Step: 5150000. Mean Reward: 17.462745098039214. Std of Reward: 7.200452803054257.\n",
      "Saved Model\n",
      "Step: 5160000. Mean Reward: 17.24771241830065. Std of Reward: 7.453766736209259.\n",
      "Step: 5170000. Mean Reward: 17.87908496732026. Std of Reward: 6.960118919376702.\n",
      "Step: 5180000. Mean Reward: 17.54155844155844. Std of Reward: 7.305345857024185.\n",
      "Step: 5190000. Mean Reward: 17.58921568627451. Std of Reward: 7.40759180694482.\n",
      "Step: 5200000. Mean Reward: 16.958387096774196. Std of Reward: 7.318464979530045.\n",
      "Saved Model\n",
      "Step: 5210000. Mean Reward: 18.231372549019607. Std of Reward: 7.01984321546457.\n",
      "Step: 5220000. Mean Reward: 17.31503267973856. Std of Reward: 7.639861676551515.\n",
      "Step: 5230000. Mean Reward: 17.49248366013072. Std of Reward: 7.444583439629264.\n",
      "Step: 5240000. Mean Reward: 17.96217948717949. Std of Reward: 6.963971779246618.\n",
      "Step: 5250000. Mean Reward: 16.658823529411762. Std of Reward: 7.692059647614083.\n",
      "Saved Model\n",
      "Step: 5260000. Mean Reward: 18.24805194805195. Std of Reward: 7.143230568751113.\n",
      "Step: 5270000. Mean Reward: 17.471935483870965. Std of Reward: 7.722144704325822.\n",
      "Step: 5280000. Mean Reward: 17.561842105263157. Std of Reward: 7.5729603317061915.\n",
      "Step: 5290000. Mean Reward: 17.427272727272726. Std of Reward: 6.914031683498783.\n",
      "Step: 5300000. Mean Reward: 18.484313725490196. Std of Reward: 6.954333934802075.\n",
      "Saved Model\n",
      "Step: 5310000. Mean Reward: 18.35424836601307. Std of Reward: 7.591681351468585.\n",
      "Step: 5320000. Mean Reward: 17.23409090909091. Std of Reward: 7.897806502452253.\n",
      "Step: 5330000. Mean Reward: 18.450986842105266. Std of Reward: 6.597157158865797.\n",
      "Step: 5340000. Mean Reward: 18.165064102564102. Std of Reward: 6.91105213860795.\n",
      "Step: 5350000. Mean Reward: 18.676948051948052. Std of Reward: 6.876244003429779.\n",
      "Saved Model\n",
      "Step: 5360000. Mean Reward: 18.22171052631579. Std of Reward: 7.2684716391299595.\n",
      "Step: 5370000. Mean Reward: 17.276797385620917. Std of Reward: 7.5275985158922865.\n",
      "Step: 5380000. Mean Reward: 17.736688311688315. Std of Reward: 6.878120406871474.\n",
      "Step: 5390000. Mean Reward: 17.91967741935484. Std of Reward: 7.081706320659644.\n",
      "Step: 5400000. Mean Reward: 19.065562913907282. Std of Reward: 6.154848370021991.\n",
      "Saved Model\n",
      "Step: 5410000. Mean Reward: 18.373548387096772. Std of Reward: 6.747337132283442.\n",
      "Step: 5420000. Mean Reward: 18.062745098039215. Std of Reward: 7.062696649843084.\n",
      "Step: 5430000. Mean Reward: 18.594771241830067. Std of Reward: 6.783265075049673.\n",
      "Step: 5440000. Mean Reward: 18.57251655629139. Std of Reward: 7.449378143613538.\n",
      "Step: 5450000. Mean Reward: 17.629032258064516. Std of Reward: 7.338207285178699.\n",
      "Saved Model\n",
      "Step: 5460000. Mean Reward: 16.8858064516129. Std of Reward: 7.559639765352172.\n",
      "Step: 5470000. Mean Reward: 18.177814569536423. Std of Reward: 7.068474539105761.\n",
      "Step: 5480000. Mean Reward: 17.23935483870968. Std of Reward: 7.111351641172869.\n",
      "Step: 5490000. Mean Reward: 18.217549668874174. Std of Reward: 6.86376462714191.\n",
      "Step: 5500000. Mean Reward: 17.283333333333335. Std of Reward: 7.24905903118514.\n",
      "Saved Model\n",
      "Step: 5510000. Mean Reward: 18.049354838709675. Std of Reward: 8.147396154594174.\n",
      "Step: 5520000. Mean Reward: 17.749006622516557. Std of Reward: 7.314098854921143.\n",
      "Step: 5530000. Mean Reward: 17.624183006535947. Std of Reward: 7.296135839520179.\n",
      "Step: 5540000. Mean Reward: 17.465705128205133. Std of Reward: 7.018016659721431.\n",
      "Step: 5550000. Mean Reward: 17.579738562091503. Std of Reward: 7.449620418255862.\n",
      "Saved Model\n",
      "Step: 5560000. Mean Reward: 17.83954248366013. Std of Reward: 7.32858280532257.\n",
      "Step: 5570000. Mean Reward: 17.673076923076923. Std of Reward: 7.547028589620179.\n",
      "Step: 5580000. Mean Reward: 18.415999999999997. Std of Reward: 6.745436284382698.\n",
      "Step: 5590000. Mean Reward: 17.75. Std of Reward: 7.407937098226607.\n",
      "Step: 5600000. Mean Reward: 17.999668874172187. Std of Reward: 7.148381228991038.\n",
      "Saved Model\n",
      "Step: 5610000. Mean Reward: 18.00548387096774. Std of Reward: 6.783817480193476.\n",
      "Step: 5620000. Mean Reward: 18.200326797385618. Std of Reward: 7.206985302337269.\n",
      "Step: 5630000. Mean Reward: 18.984539473684208. Std of Reward: 6.3713953522979505.\n",
      "Step: 5640000. Mean Reward: 16.52467532467532. Std of Reward: 7.700339946015131.\n",
      "Step: 5650000. Mean Reward: 18.719281045751632. Std of Reward: 5.820886227763676.\n",
      "Saved Model\n",
      "Step: 5660000. Mean Reward: 18.625. Std of Reward: 6.534636115029218.\n",
      "Step: 5670000. Mean Reward: 18.444407894736845. Std of Reward: 6.866668514754197.\n",
      "Step: 5680000. Mean Reward: 18.29901960784314. Std of Reward: 7.120821147176289.\n",
      "Step: 5690000. Mean Reward: 18.058974358974357. Std of Reward: 7.046613314527109.\n",
      "Step: 5700000. Mean Reward: 17.933552631578944. Std of Reward: 6.791533468407048.\n",
      "Saved Model\n",
      "Step: 5710000. Mean Reward: 19.05960264900662. Std of Reward: 5.822341405719969.\n",
      "Step: 5720000. Mean Reward: 18.670261437908497. Std of Reward: 6.536254943759473.\n",
      "Step: 5730000. Mean Reward: 17.753246753246753. Std of Reward: 7.232111103753517.\n",
      "Step: 5740000. Mean Reward: 18.364144736842103. Std of Reward: 6.545560010226191.\n",
      "Step: 5750000. Mean Reward: 18.951623376623377. Std of Reward: 6.314252633977143.\n",
      "Saved Model\n",
      "Step: 5760000. Mean Reward: 18.40686274509804. Std of Reward: 6.983187229562291.\n",
      "Step: 5770000. Mean Reward: 18.23169934640523. Std of Reward: 7.076703360008467.\n",
      "Step: 5780000. Mean Reward: 18.803618421052633. Std of Reward: 6.542792091637751.\n",
      "Step: 5790000. Mean Reward: 18.46546052631579. Std of Reward: 6.67370930147149.\n",
      "Step: 5800000. Mean Reward: 18.395394736842103. Std of Reward: 6.494401321784275.\n",
      "Saved Model\n",
      "Step: 5810000. Mean Reward: 18.213548387096775. Std of Reward: 6.881844533491189.\n",
      "Step: 5820000. Mean Reward: 17.752287581699346. Std of Reward: 6.704143046106358.\n",
      "Step: 5830000. Mean Reward: 19.695751633986927. Std of Reward: 6.69582336825257.\n",
      "Step: 5840000. Mean Reward: 18.206089743589743. Std of Reward: 7.2248798742314255.\n",
      "Step: 5850000. Mean Reward: 17.240849673202618. Std of Reward: 7.319361551830969.\n",
      "Saved Model\n",
      "Step: 5860000. Mean Reward: 17.346815286624203. Std of Reward: 7.361796031744884.\n",
      "Step: 5870000. Mean Reward: 17.991503267973854. Std of Reward: 7.297924297180324.\n",
      "Step: 5880000. Mean Reward: 16.932565789473685. Std of Reward: 7.524653034203333.\n",
      "Step: 5890000. Mean Reward: 17.501307189542484. Std of Reward: 6.789089063887679.\n",
      "Step: 5900000. Mean Reward: 17.40288461538461. Std of Reward: 7.894336740754727.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model\n",
      "Step: 5910000. Mean Reward: 18.123856209150325. Std of Reward: 6.856948875028092.\n",
      "Step: 5920000. Mean Reward: 17.788636363636364. Std of Reward: 6.515674215164399.\n",
      "Step: 5930000. Mean Reward: 17.108387096774194. Std of Reward: 7.431940265382964.\n",
      "Step: 5940000. Mean Reward: 17.68474025974026. Std of Reward: 6.980686082276458.\n",
      "Step: 5950000. Mean Reward: 17.825806451612902. Std of Reward: 6.982917762559433.\n",
      "Saved Model\n",
      "Step: 5960000. Mean Reward: 17.333774834437087. Std of Reward: 7.886052214223501.\n",
      "Step: 5970000. Mean Reward: 18.49967741935484. Std of Reward: 6.8143172255759.\n",
      "Step: 5980000. Mean Reward: 17.835064935064935. Std of Reward: 7.310948758473841.\n",
      "Step: 5990000. Mean Reward: 17.9375. Std of Reward: 7.062973901193983.\n",
      "Step: 6000000. Mean Reward: 17.80588235294118. Std of Reward: 7.327609042983445.\n",
      "Saved Model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fea09393b070>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# Decide and take an action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mnew_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrain_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_experiences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_horizon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Repo\\Don-t-Let-Me-Fall\\python\\ppo\\trainer.py\u001b[0m in \u001b[0;36mtake_action\u001b[1;34m(self, info, env, brain_name, steps, normalize)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'entropy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mnew_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_experiences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Repo\\Don-t-Let-Me-Fall\\python\\unityagents\\environment.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action, memory, value)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb\"STEP\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loaded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUnityEnvironmentException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No Unity environment is loaded.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Repo\\Don-t-Let-Me-Fall\\python\\unityagents\\environment.py\u001b[0m in \u001b[0;36m_get_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_brains\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m             \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"brain_name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0mn_agent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"agents\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Repo\\Don-t-Let-Me-Fall\\python\\unityagents\\environment.py\u001b[0m in \u001b[0;36m_get_state_dict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \"\"\"\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb\"RECEIVED\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Repo\\Don-t-Let-Me-Fall\\python\\unityagents\\environment.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m             \u001b[0mmessage_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"I\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "if curriculum_file == \"None\":\n",
    "    curriculum_file = None\n",
    "\n",
    "\n",
    "def get_progress():\n",
    "    if curriculum_file is not None:\n",
    "        if env._curriculum.measure_type == \"progress\":\n",
    "            return steps / max_steps\n",
    "        elif env._curriculum.measure_type == \"reward\":\n",
    "            return last_reward\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create the Tensorflow model graph\n",
    "ppo_model = create_agent_model(env, lr=learning_rate,\n",
    "                               h_size=hidden_units, epsilon=epsilon,\n",
    "                               beta=beta, max_step=max_steps, \n",
    "                               normalize=normalize, num_layers=num_layers)\n",
    "\n",
    "is_continuous = (env.brains[brain_name].action_space_type == \"continuous\")\n",
    "use_observations = (env.brains[brain_name].number_observations > 0)\n",
    "use_states = (env.brains[brain_name].state_space_size > 0)\n",
    "\n",
    "model_path = './models/{}'.format(run_path)\n",
    "summary_path = './summaries/{}'.format(run_path)\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "if not os.path.exists(summary_path):\n",
    "    os.makedirs(summary_path)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Instantiate model parameters\n",
    "    if load_model:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "    steps, last_reward = sess.run([ppo_model.global_step, ppo_model.last_reward])    \n",
    "    summary_writer = tf.summary.FileWriter(summary_path)\n",
    "    info = env.reset(train_mode=train_model, progress=get_progress())[brain_name]\n",
    "    trainer = Trainer(ppo_model, sess, info, is_continuous, use_observations, use_states, train_model)\n",
    "    if train_model:\n",
    "        trainer.write_text(summary_writer, 'Hyperparameters', hyperparameter_dict, steps)\n",
    "    while steps <= max_steps:\n",
    "        if env.global_done:\n",
    "            info = env.reset(train_mode=train_model, progress=get_progress())[brain_name]\n",
    "        # Decide and take an action\n",
    "        new_info = trainer.take_action(info, env, brain_name, steps, normalize)\n",
    "        info = new_info\n",
    "        trainer.process_experiences(info, time_horizon, gamma, lambd)\n",
    "        if len(trainer.training_buffer['actions']) > buffer_size and train_model:\n",
    "            # Perform gradient descent with experience buffer\n",
    "            trainer.update_model(batch_size, num_epoch)\n",
    "        if steps % summary_freq == 0 and steps != 0 and train_model:\n",
    "            # Write training statistics to tensorboard.\n",
    "            trainer.write_summary(summary_writer, steps, env._curriculum.lesson_number)\n",
    "        if steps % save_freq == 0 and steps != 0 and train_model:\n",
    "            # Save Tensorflow model\n",
    "            save_model(sess, model_path=model_path, steps=steps, saver=saver)\n",
    "        steps += 1\n",
    "        sess.run(ppo_model.increment_step)\n",
    "        if len(trainer.stats['cumulative_reward']) > 0:\n",
    "            mean_reward = np.mean(trainer.stats['cumulative_reward'])\n",
    "            sess.run(ppo_model.update_reward, feed_dict={ppo_model.new_reward: mean_reward})\n",
    "            last_reward = sess.run(ppo_model.last_reward)\n",
    "    # Final save Tensorflow model\n",
    "    if steps != 0 and train_model:\n",
    "        save_model(sess, model_path=model_path, steps=steps, saver=saver)\n",
    "env.close()\n",
    "export_graph(model_path, env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the trained Tensorflow graph\n",
    "Once the model has been trained and saved, we can export it as a .bytes file which Unity can embed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/ppo\\model-6000000.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/ppo\\model-6000000.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "export_graph(model_path, env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
